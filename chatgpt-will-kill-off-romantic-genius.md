# ChatGPT will kill off the Romantic genius

Link: [ChatGPT will kill off the Romantic genius - UnHerd](https://unherd.com/2024/01/chatgpt-will-kill-off-the-romantic-genius/?tl_inbound=1&tl_groups)

A defence of using algorithms to make art.

The author doesn't think that Rie Kudan cheated when writing [The Tokyo Tower of Sympathy](the-tokyo-tower-of-sympathy) with the help of #gpt.

>We could counter, further, that ChatGPT didn’t decide which 5% of the novel was going to be by ChatGPT, nor which bits of ChatGPT’s language were going in there.

The author still had to do "work" with the AI-generated content.

>Didn’t Roland Barthes pronounce The Death of the Author as long ago as 1967?

>Chaucer was forever talking about “myn auctor”, and a text that came adapted from a precedent was seen as more trustworthy and high-status than one that didn’t. Milton reworked the Bible, Shakespeare reworked Holinshed, and so on and so forth.

Artists copying from each other is lindy.

>In 1920, the Dadaist eminence Tristan Tzara announced that poetry could be written by taking a newspaper article of the length you wanted your poem to be, cutting it into its constituent words with a pair of scissors, shaking them about in a bag and then transcribing them in the random order in which they emerged. There’s a funny bit about it in Tom Stoppard’s play Travesties.

>That was only the starting gun for all manner of literary jiggery-pokery. William S. Burroughs and his collaborator Brion Gysin picked up Tzara’s baton in the Sixties, experimenting with “cut-ups” (much like Dada poetry) and “fold-ins” (where you would fold two pages of an existing book together so the edges met, and read across the fold to make a new text). The fantasy writer Jeff Noon’s 2001 book, Cobralingus, presented a set of algorithmic instructions for transforming a text through what Noon called “filter gates”, something analogous to a DJ remixing a record.

Using algorithms to create writing is also not new.

>Arbitrary literary constraints or outright randomness, then — which is to say, things outside the author’s control which help determine the final text — have a very honourable place in literary history. You could even see the sonnet form or the villanelle as a species of algorithm.

This could be freeing rather than restricting.

>Only that it’s a very narrow and regressive view of literature to see handing over control of some of your text to chance or to an algorithm as “cheating”. It’s what you do with the result that counts, and what Ms Kudan did was apparently, well, flawless.

>You could even make the case, perhaps, that 5% of Ms Kudan’s prize money should rightfully be distributed to every Japanese language author on whose copyright work the algorithm was trained. 

To make things fair...

>Indeed, if you were of a literary-theoretical cast of mind you could point out what Tzara and his successors were gesturing to in an oblique way anyway: intertextuality. Every text, in the end, is made of other texts. Every word in a novel or poem is a borrowing: it depends for its meaning on the vast constellation of other contexts in which it has appeared, and through which its reader will understand it. Every author, in his or her individual way, is a meat-brained ChatGPT, “trained” on a lifetime’s reading of classics and copyright works.

Everyone is doing what ChatGPT is doing?

>The Romantic model of the artist is underscored, after all, by a reassuring idea about humanity: that we are creators not creations, that what makes us distinctive isn’t simply a neurological compost of our inputs but some ineffable inner essence that can only be captured in the act of expression.

>Is it possible, then, that we so fiercely police the distinction between what Large Language Models can do and human creativity because we’re… touchy about it? That we’re worried it may be a temporary distinction of degree rather than a fundamental difference of category; which is to say, no distinction at all?

